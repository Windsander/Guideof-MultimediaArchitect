
# 4.2 模型结构速览

在深度学习（DL）中，我们通过计算损失函数（Loss Function），来衡量当次迭代结果对应各个关键参数权重，在实际描述问题上的有效程度。通过损失函数的变化方向，来获取对应关键参数权重，更趋近于实际结果的梯度方向。从而被我们使用来更新当前参数权重配置，以降低损失函数值，逼近最优解。这一过程被称为一次迭代（Iteration）过程。而通过多次迭代来获取最优解的过程，被称为一次训练（Training）。

在一次迭代（Iteration）中，一般需要对参与训练的所有样本进行分组，我们将这些数据子集称为 **批（Batch）** 。每一批所包含的数据量是有可能有差异的，所以，对不同批次的样本量，我们采用 **批大小（Batch Size）** 进行衡量。

而训练中，基本不可能通过单次迭代就能达到想要的结果。所以，在工程中，我们把一次迭代所包含的相关数据和处理的周期过程，称为一个 **时期（Epoch）** 。用以区分深度学习学术概念的迭代，和工程执行层面的差异。因此，时期（Epoch）也可以代表数量级，即指代当前一次迭代过程中的所有批的输入样本个数。 **两者本质是一个概念的不同角度称呼。**

简单来说：

$$
{\displaystyle 
 \begin{aligned}
   {sample}_{input} &\le {sample}_{total} \\
   1\ epoch_{size} &= {sample}_{input} \\
                    &\ge batch_{size} \cdot batch_{num} \\
   1\ batch_{size} &= \frac{ {sample}_{input} } {batch_{num}} \\
 \end{aligned}
}
$$

皆为训练过程中的量级参数。

那么，除去变量，实际进行运算的基本单元是什么呢？


[ref]: References_4.md