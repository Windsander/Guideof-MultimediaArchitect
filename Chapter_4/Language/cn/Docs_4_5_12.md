
# 4.5.12 正则项-L2 惩罚

**迭代公式：**

$$
{\displaystyle 
 \begin{aligned}
   L_2 = {w_1}^2+{w_2}^2+{w_3}^2+ \cdots +{w_n}^2 \\
 \end{aligned}
}
$$

**特性：**

1. 根据参数权重平方和，来惩罚权重
2. L-2 导数为 2x，所有权重变化非线性，可以以此区分参数主次（模型层面）
3. 无法使不相关或几乎不相关权重归 0，无法从模型中移除不相关特征
4. 平滑连续，权重变化自然 
5. 平方计算，非指数，可接受


**L-2 惩罚项（$$L_2$$ Regularity）** 最大的特点就是平滑（smooth）。这决定了在实际运算过程中，L-2 惩罚项只有办法让权重趋近于 0 ，而无法彻底移出对应参数。但是这种特点也使得，L-2 惩罚项可以通过非线性权重，调整模型相关参数在模型中的重要程度。

因此，L-2 惩罚项也被称为 **权重衰减（Weight Decay）** 。并不能消除不相关特征，但能较好的保证特征和结果的因果关系。

至此，损失函数的三类组成部分认识完毕。其实我们只做了粗浅的介绍，真正实用中，还有大量的细分和类型设计。除了少数我们介绍的经典如 MAE、MSE 等，每一个新的损失函数，都可能意味着有自己独特的配套神经网络结构。

究其原因，还是在于损失函数作用的范围，在于衡量整个网络的迭代，这决定了它不太可能会脱离而存在。使用中，需要小心。


[ref]: References_4.md